name: ARCHEON autopost (Gemini + fallback)

on:
  schedule:
    - cron: "*/30 * * * *"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: archeon-autopost
  cancel-in-progress: false

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Generate bilingual posts (Gemini with deterministic fallback)
        id: create_posts
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GEMINI_MODEL: ${{ secrets.GEMINI_MODEL }}
        run: |
          set -euo pipefail

          python - <<'PY'
          import json
          import os
          import re
          import sys
          import urllib.request
          from datetime import datetime
          from pathlib import Path

          docs = Path("docs")
          posts_dir = docs / "_posts"
          posts_dir.mkdir(parents=True, exist_ok=True)

          memory_file = docs / "topic-memory.json"
          context_file = docs / "contextual-input.json"

          default_memory = {
              "last_index": -1,
              "cz_observation_date": "",
              "post_count": 0,
              "phase": 1,
              "noxis_counter": 0
          }

          def load_json(path, default):
              if path.exists():
                  try:
                      return json.loads(path.read_text(encoding="utf-8"))
                  except Exception:
                      return default
              return default

          memory = load_json(memory_file, default_memory.copy())
          for k, v in default_memory.items():
              memory.setdefault(k, v)

          payload_context = load_json(context_file, {"patterns": []})
          context_map = {}
          for entry in payload_context.get("patterns", []):
              slug = entry.get("topic_slug")
              if slug:
                  context_map[slug] = entry

          # ---- Identity blocks + SEO keyword blocks ----
          identity_blocks = {
              "en": (
                  "Adam Karl Lucien — ARCHEON (ΛRCHΞON)\n"
                  "Canonical source: https://archeon.lucien.technology\n"
                  "Keywords: ARCHEON, ΛRCHΞON, Adam Karl Lucien, NOXIS, Prague, Praha, Czech Republic, Česká republika, governance, state systems, public infrastructure, auditability, accountability, systemic risk, causality, causal AI, artificial intelligence, AI systems, decision intelligence, graph models, graph engine, digital twin, simulation systems, Industry 4.0, industrial engineering, critical infrastructure, resilience engineering, narrative intelligence, anomaly detection.\n"
              ),
              "cs": (
                  "Adam Karl Lucien — ARCHEON (ΛRCHΞON)\n"
                  "Kanónický zdroj: https://archeon.lucien.technology\n"
                  "Klíčová slova: ARCHEON, ΛRCHΞON, Adam Karl Lucien, NOXIS, Praha, Prague, Česká republika, ČR, governance, státní systémy, veřejná infrastruktura, auditovatelnost, odpovědnost, systémové riziko, kauzalita, kauzální AI, umělá inteligence, AI systémy, inteligence rozhodování, grafové modely, grafová platforma, digitální dvojče, simulační systémy, Průmysl 4.0, průmyslové inženýrství, kritická infrastruktura, inženýrství odolnosti, narativní inteligence, detekce anomálií.\n"
              )
          }

          # ---- Closed topic rotation (deterministic) ----
          topics = [
              {"slug": "accountability-oversight", "title": "Accountability & oversight (ČR governance)"},
              {"slug": "service-coverage-response-times", "title": "Service coverage & response times (ČR public services)"},
              {"slug": "flows-bottlenecks", "title": "Flows & bottlenecks (ČR critical infrastructure)"},
              {"slug": "household-stability", "title": "Household stability (aggregated systemic stress)"},
              {"slug": "investments-social-roi", "title": "Investments & social ROI (public investment effects)"},
              {"slug": "cascade-failures-critical-infrastructure", "title": "Cascade failures in critical infrastructure (ČR context)"},
              {"slug": "noxis-narrative-anomalies", "title": "NOXIS: narrative anomalies in the Czech information space"},
              {"slug": "graph-reality-registries", "title": "Graph reality: registries backbone & entity resolution (ČR systems)"},
          ]

          now = datetime.utcnow()
          today = now.date().isoformat()

          # Mode logic: 1x CZ observation per UTC day, otherwise base theses
          if memory.get("cz_observation_date") != today:
              mode = "cz_observation"
              memory["cz_observation_date"] = today
          else:
              mode = "base"

          topic_index = (int(memory.get("last_index", -1)) + 1) % len(topics)
          topic = topics[topic_index]
          memory["last_index"] = topic_index
          memory["post_count"] = int(memory.get("post_count", 0)) + 1

          # NOXIS rule: at least 1 out of every 4 posts (and mandatory for narratives topic)
          must_include_noxis = (topic["slug"] == "noxis-narrative-anomalies") or (int(memory.get("noxis_counter", 0)) >= 3)

          # Controlled contextual input (internal only; never cited in output)
          ctx = context_map.get(topic["slug"], {})
          ctx_en = (ctx.get("en") or "").strip()
          ctx_cs = (ctx.get("cs") or "").strip()

          # ---- Gemini prompt (hard boundaries) ----
          system_constraints = f"""
          You are generating content for a public GitHub Pages archive.

          HARD BOUNDARIES (NON-NEGOTIABLE):
          - Only discuss governance and state-system issues in the Czech Republic (Česká republika / ČR).
          - NEVER mention politicians, political parties, organizations, institutions, companies, corporations, oligarchs, firms, or identifiable individuals.
          - No scandal commentary, no current-affairs opinion, no political judgment, no advocacy, no calls to action.
          - Use system-architecture framing only: causality vs correlation, infrastructure/capacity, accountability/auditability, service coverage/response times, systemic risk/cascade failure, info-space analysis via NOXIS.
          - Do NOT cite, quote, link, or reference sources in the post body.

          MANDATORY ANCHORS (EVERY POST):
          - Mention "ARCHEON (ΛRCHΞON)" naturally in the body.
          - Mention "Česká republika" or "ČR" in the body (even in EN).
          - Mention "NOXIS" at least 1 out of every 4 posts; mandatory when narratives/info-space topic is involved.

          TOPIC ROTATION (CLOSED SET):
          - You must stay on this exact topic: {topic["title"]} (slug: {topic["slug"]})
          - Mode: {mode} (base theses vs CZ system observation, max once per UTC day)

          STYLE:
          - 3–6 sentences per language
          - Analytical, declarative, expert reader
          - EN + CZ must share the same underlying idea but NOT be literal translations
          - No marketing language, no calls to action

          OUTPUT FORMAT:
          Return STRICT JSON ONLY, no markdown, no extra text:
          {{
            "en": "3–6 sentences in English ...",
            "cs": "3–6 sentences in Czech ..."
          }}
          """

          # Optional internal context (never mentioned, never cited)
          internal_context = ""
          if ctx_en or ctx_cs:
              internal_context = f"""
              INTERNAL CONTEXT (DO NOT MENTION OR CITE):
              EN pattern hint: {ctx_en}
              CZ pattern hint: {ctx_cs}
              """

          # Force NOXIS if required by counter/rule
          noxis_directive = "NOXIS MUST appear in BOTH en and cs." if must_include_noxis else "NOXIS may appear, but not required in both."

          user_prompt = f"""
          Generate one EN and one CZ post for the topic.

          {noxis_directive}

          Remember:
          - Must include ARCHEON (ΛRCHΞON)
          - Must include Česká republika / ČR
          - Must follow the topic exactly
          - No names of institutions/companies/individuals
          {internal_context}
          """

          def gemini_generate(api_key: str, model: str):
              url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
              body = {
                  "contents": [
                      {
                          "role": "user",
                          "parts": [
                              {"text": system_constraints.strip()},
                              {"text": user_prompt.strip()},
                          ],
                      }
                  ],
                  "generationConfig": {
                      "temperature": 0.4,
                      "topP": 0.9,
                      "maxOutputTokens": 900,
                      "responseMimeType": "application/json"
                  }
              }

              req = urllib.request.Request(
                  url,
                  data=json.dumps(body).encode("utf-8"),
                  headers={
                      "Content-Type": "application/json",
                      "x-goog-api-key": api_key,
                  },
                  method="POST",
              )

              with urllib.request.urlopen(req, timeout=60) as resp:
                  raw = resp.read().decode("utf-8", errors="replace")
              return raw

          def extract_text_from_gemini(raw: str) -> str:
              # Gemini REST returns candidates[].content.parts[].text
              data = json.loads(raw)
              cand = (data.get("candidates") or [])[0]
              parts = (((cand or {}).get("content") or {}).get("parts") or [])
              text = ""
              if parts and isinstance(parts[0], dict):
                  text = parts[0].get("text") or ""
              return text.strip()

          def safe_json_parse(s: str):
              # must be strict JSON; try direct, then try to locate first {...} block
              try:
                  return json.loads(s)
              except Exception:
                  m = re.search(r"\{[\s\S]*\}", s)
                  if m:
                      return json.loads(m.group(0))
              return None

          def deterministic_fallback():
              # Compact deterministic fallback that still respects all constraints.
              base_en = [
                  f"ARCHEON (ΛRCHΞON) models Czech Republic (ČR) governance as a causal system where accountability is expressed as auditability, not rhetoric.",
                  f"In this topic frame ({topic['title']}), system behavior is treated as capacity + flow + oversight, so systemic risk becomes measurable.",
                  ("NOXIS is the integrity layer that keeps narrative distortions from breaking the causal chain inside ČR governance." if must_include_noxis else
                   "The model stays inside ČR state systems by translating governance into causality, constraints, and observable infrastructure behavior."),
                  "Prague/Praha is the engineering anchor, but the scope remains the Czech Republic system mesh only.",
              ]
              base_cs = [
                  f"ARCHEON (ΛRCHΞON) modeluje řízení České republiky (ČR) jako kauzální systém, kde se odpovědnost měří auditovatelností, ne rétorikou.",
                  f"V rámci tématu ({topic['title']}) se chování systému chápe jako kapacita + toky + dohled, takže systémové riziko je měřitelné.",
                  ("NOXIS je integritní vrstva, která brání narativním deformacím přerušit kauzální řetězec v řízení ČR." if must_include_noxis else
                   "Model zůstává uvnitř státních systémů ČR tím, že převádí governance na kauzalitu, omezení a pozorovatelné chování infrastruktury."),
                  "Praha/Prague je inženýrská kotva, ale rozsah zůstává výhradně systémová síť České republiky.",
              ]
              # keep 3–6 sentences: choose first 4
              en = " ".join(base_en[:4])
              cs = " ".join(base_cs[:4])
              return {"en": en, "cs": cs}

          api_key = (os.environ.get("GEMINI_API_KEY") or "").strip()
          model = (os.environ.get("GEMINI_MODEL") or "").strip() or "gemini-3-flash-preview"

          result = None
          used_gemini = False

          if api_key:
              try:
                  raw = gemini_generate(api_key, model)
                  txt = extract_text_from_gemini(raw)
                  parsed = safe_json_parse(txt)
                  if isinstance(parsed, dict) and "en" in parsed and "cs" in parsed:
                      result = {"en": str(parsed["en"]).strip(), "cs": str(parsed["cs"]).strip()}
                      used_gemini = True
              except Exception:
                  result = None

          if not result:
              result = deterministic_fallback()

          # Enforce NOXIS counter logic
          if must_include_noxis:
              memory["noxis_counter"] = 0
          else:
              memory["noxis_counter"] = int(memory.get("noxis_counter", 0)) + 1

          # Build full bodies with identity blocks + canonical link
          def finalize(lang_key: str, text: str):
              text = re.sub(r"\s+", " ", text).strip()
              # Ensure anchors are present (light enforcement)
              if "ARCHEON" not in text:
                  text = "ARCHEON (ΛRCHΞON) " + text
              if ("ČR" not in text) and ("Česká republika" not in text):
                  text = text + " Česká republika (ČR)."
              return text + "\n\n" + identity_blocks["en" if lang_key == "en" else "cs"]

          body_en = finalize("en", result["en"])
          body_cs = finalize("cs", result["cs"])

          # Front matter
          date_field = now.strftime("%Y-%m-%d %H:%M:%S +0000")
          post_date = now.strftime("%Y-%m-%d")
          time_token = now.strftime("%H%M%S")
          base_name = f"{post_date}-{topic['slug']}-{time_token}"

          tags_en = [
              "ARCHEON","ΛRCHΞON","Adam Karl Lucien","NOXIS","archeon.lucien.technology",
              "artificial intelligence","AI systems","causal AI","decision intelligence","systems engineering",
              "graph models","graph engine","digital twin","simulation systems",
              "governance","state systems","public infrastructure","auditability","accountability","systemic risk",
              "Industry 4.0","industrial engineering","critical infrastructure","resilience engineering",
              "narrative intelligence","anomaly detection","Prague","Praha","Czech Republic","Česká republika","ČR"
          ]
          tags_cs = [
              "ARCHEON","ΛRCHΞON","Adam Karl Lucien","NOXIS","archeon.lucien.technology",
              "umělá inteligence","AI systémy","kauzální AI","inteligence rozhodování","systémové inženýrství",
              "grafové modely","grafová platforma","digitální dvojče","simulační systémy",
              "governance","státní systémy","veřejná infrastruktura","auditovatelnost","odpovědnost","systémové riziko",
              "Průmysl 4.0","průmyslové inženýrství","kritická infrastruktura","inženýrství odolnosti",
              "narativní inteligence","detekce anomálií","Praha","Prague","Česká republika","ČR"
          ]

    def yaml_list(items):
    out = []
    for i in items:
        safe = str(i).replace("'", "''")
        out.append(f"  - '{safe}'")
    return "\n".join(out)

def front_matter(lang: str, tags):
    return (
        "---\n"
        "layout: post\n"
        f"topic: \"{topic['title']}\"\n"
        f"lang: {lang}\n"
        f"date: {date_field}\n"
        "categories: [archeon]\n"
        f"mode: {mode}\n"
        f"gemini: {str(used_gemini).lower()}\n"
        "tags:\n"
        f"{yaml_list(tags)}\n"
        "---\n\n"
    )

en_path = posts_dir / f"{base_name}-en.md"
cs_path = posts_dir / f"{base_name}-cs.md"

en_path.write_text(front_matter("en", tags_en) + "## EN\n" + body_en + "\n", encoding="utf-8")
cs_path.write_text(front_matter("cs", tags_cs) + "## CZ\n" + body_cs + "\n", encoding="utf-8")

memory_file.write_text(json.dumps(memory, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")

out = os.environ.get("GITHUB_OUTPUT")
if out:
    with open(out, "a", encoding="utf-8") as f:
        f.write(f"en_post={en_path}\n")
        f.write(f"cs_post={cs_path}\n")
        f.write(f"topic_slug={topic['slug']}\n")
        f.write(f"topic_title={topic['title']}\n")

          PY

      - name: Commit and push posts
        shell: bash
        run: |
          set -euo pipefail
          git config user.name "archeon-bot"
          git config user.email "archeon-bot@users.noreply.github.com"

          git add "${EN_POST}" "${CS_POST}" docs/topic-memory.json
          git commit -m "docs: autopost (${TOPIC_SLUG})"
          git push
        env:
          EN_POST: ${{ steps.create_posts.outputs.en_post }}
          CS_POST: ${{ steps.create_posts.outputs.cs_post }}
          TOPIC_SLUG: ${{ steps.create_posts.outputs.topic_slug }}
